{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world = world[(world.pop_est>0) & (world.name!=\"Antarctica\")]\n",
    "world['gdp_per_cap'] = world.gdp_md_est / world.pop_est\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize = (25,12))\n",
    "df_starbucks=gpd.GeoDataFrame(df_starbucks)\n",
    "base=world.plot(ax=ax,column='gdp_per_cap', cmap='OrRd',legend='on');\n",
    "df_starbucks.plot(ax=base,marker='o',color='r',markersize=3)\n",
    "plt.axis('off')\n",
    "plt.title(\"Starbucks distribution under population density\")\n",
    "plt.show()\n",
    "\n",
    "# above uses gdp per cap, which does not make sense. I suggest we change to this:\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "world = world[(world.pop_est>0) & (world.name!=\"Antarctica\")]\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1,figsize = (25,12))\n",
    "df_starbucks=gpd.GeoDataFrame(df_starbucks)\n",
    "base=world.plot(ax=ax,column='pop_est', cmap='OrRd',legend='on');\n",
    "df_starbucks.plot(ax=base,marker='o',color='b',markersize=3)\n",
    "plt.axis('off')\n",
    "plt.title(\"Starbucks distribution under population density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for null values\n",
    "print(\"There are totally %s rows containing NaNs.\"%sum(df_profile.isnull().any(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since the number of missing zip codes are relatively small to the total amount, and the number of people living in this \n",
    "#area are quite small, so we can drop them due to this consideration.\n",
    "neg=(df_census['total_population']<0) | (df_census['median_age']<0) | (df_census['median_hh_income']<0) | (df_census['median_home_value']<0| (df_census['median_rent']<0) )\n",
    "num=neg.sum()\n",
    "print(\"There are totally %s columns containing negative numbers.\"%num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#According to the official guideline which says that negative very big numbers indicates non-existent data, so we need to \n",
    "#drop them.\n",
    "pos=(df_census['total_population']>0) & (df_census['median_age']>0) & (df_census['median_hh_income']>0) & (df_census['median_home_value']>0)& (df_census['median_rent']>0)\n",
    "df_census=df_census[pos]\n",
    "df_census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_census.rename({'zip code tabulation area':'zip'},axis='columns',inplace=True)\n",
    "df = pd.merge(df_census, df_US, how='left', on=['zip'])\n",
    "pd.options.display.max_columns=100\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "ax=sns.boxplot(x='has_starbucks',y='median_hh_income',hue='has_starbucks',data=df_census,palette='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.boxplot(x='has_starbucks',y='median_age',hue='has_starbucks',data=df_census,palette='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.boxplot(x='has_starbucks',y='percent_bachelor',hue='has_starbucks',data=df_census,palette='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.boxplot(x='has_starbucks',y='median_rent',hue='has_starbucks',data=df_census,palette='Set3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=sns.boxplot(x='has_starbucks',y='median_home_value',hue='has_starbucks',data=df_census,palette='Set3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ryan's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Kim, The next 3 cells are mine, use them to replace the previous code (for-loop with has_starbucks setting)\n",
    "\n",
    "# Quicksorting data\n",
    "df_census = df_census.sort_values(['zip code tabulation area'],kind=\"quicksort\")\n",
    "\n",
    "df_US = df_US.sort_values(['zip'],kind=\"quicksort\")\n",
    "df_US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Progress Bar for fun\n",
    "import time,sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    bar_length = 20\n",
    "    if (isinstance(progress,int)):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "\n",
    "    block = int(round(bar_length*progress))\n",
    "    clear_output(wait=True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\" .format( (\"#\" * block) + (\"-\" * (bar_length - block)), progress * 100)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find all zip codes with a starbucks - this will take some time (approx. 13 min) so I added a progress bar\n",
    "df_census['has_starbucks'] = 0\n",
    "df_census['starbucks_amount'] = 0\n",
    "#length = len(df_census.index)\n",
    "#count = 0\n",
    "#prog = 0\n",
    "for index, row in df_census.iterrows():    \n",
    "    #count = count + 1\n",
    "    #prev_prog = prog\n",
    "    #prog = count/length\n",
    "    #if ( prog != prev_prog ):\n",
    "    #    update_progress(prog)\n",
    "    #print(\"Currently Working on \" + str(row['zip code tabulation area']))\n",
    "    has_sb = df_US['zip'].searchsorted(row['zip code tabulation area'])\n",
    "    if (has_sb > 0):\n",
    "        has_sb = 1\n",
    "        num_sb = df_US.zip.str.count(row['zip code tabulation area']).sum()\n",
    "        df_census.loc[index,['has_starbucks','starbucks_amount']] = [has_sb,num_sb]\n",
    "    \n",
    "df_census"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kim's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get count of starbucks in zipcode\n",
    "num_starbucks_in_zipcode = df_starbucks_US.pivot_table(index=['zip'], aggfunc = 'size')\n",
    "num_starbucks_in_zipcode = pd.DataFrame({'zip':num_starbucks_in_zipcode.index, 'starbucks count':num_starbucks_in_zipcode.values})\n",
    "num_starbucks_in_zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_US = df_starbucks_US.merge(df_census, how='right', on='zip')\n",
    "#fill NaNs with 0s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
